

CUDA_VISIBLE_DEVICES=4 python src/main.py \
    --mode base \
    --exp_name llama2_base \
    --model_dir /nobackup2/froilan/checkpoints/llama-2/Llama-2-7b-chat-hf/ \
    --verbose
