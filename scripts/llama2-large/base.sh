

CUDA_VISIBLE_DEVICES=2 python src/main.py \
    --mode base \
    --exp_name llama2large_base \
    --model_dir /nobackup2/froilan/checkpoints/llama-2/Llama-2-13b-chat-hf/ \
    --verbose
